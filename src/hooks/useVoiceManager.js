import { useEffect, useRef, useCallback } from 'react';
import { useAppStore } from '../store/appStore';
import { meditations, spiritualMeditations } from '../data/meditations';

export const useVoiceManager = () => {
  const { 
    voiceSettings, 
    currentSession, 
    currentMeditation,
    isSessionActive
  } = useAppStore();
  
  const synth = useRef(window.speechSynthesis);
  const voices = useRef([]);
  const currentUtterance = useRef(null);
  const isInitialized = useRef(false);
  const sessionGuidanceStarted = useRef(false);
  const sessionGuidancePhase = useRef(0);
  const lastSpeakTime = useRef(0);
  const audioElementRef = useRef(null);
  const audioQueue = useRef([]);
  const isPlayingAudio = useRef(false);
  const timeoutsRef = useRef([]);
  const fullAudioRef = useRef(null);
  
  // Fonction pour cr√©er un timeout qui sera automatiquement suivi
  const createTrackedTimeout = useCallback((callback, delay) => {
    const timeoutId = setTimeout(() => {
      // Supprimer ce timeout de la liste des timeouts actifs
      timeoutsRef.current = timeoutsRef.current.filter(id => id !== timeoutId);
      callback();
    }, delay);
    
    // Ajouter ce timeout √† la liste des timeouts actifs
    timeoutsRef.current.push(timeoutId);
    
    return timeoutId;
  }, []);
  
  // Fonction pour nettoyer tous les timeouts
  const clearAllTimeouts = useCallback(() => {
    console.log(`üßπ Nettoyage de TOUS les timeouts (${timeoutsRef.current.length} timeouts actifs)`);
    
    timeoutsRef.current.forEach(id => {
      clearTimeout(id);
    });
    
    // Vider la liste des timeouts
    timeoutsRef.current = [];
    
    console.log('‚úÖ Tous les timeouts ont √©t√© nettoy√©s');
  }, []);
  
  // Initialiser les voix
  useEffect(() => {
    const initVoices = () => {
      if (synth.current) {
        voices.current = synth.current.getVoices().filter(voice => 
          voice.lang.includes('fr') || voice.name.includes('French')
        );
        
        if (voices.current.length > 0) {
          isInitialized.current = true;
          console.log('üé§ Voix fran√ßaises disponibles:', voices.current.length);
        } else {
          console.log('‚ö†Ô∏è Aucune voix fran√ßaise trouv√©e, utilisation de la voix par d√©faut');
          voices.current = synth.current.getVoices();
          isInitialized.current = true;
        }
      }
    };
    
    // Initialiser les voix au chargement
    if (synth.current) {
      if (synth.current.getVoices().length > 0) {
        initVoices();
      }
      
      // √âcouter l'√©v√©nement voiceschanged
      synth.current.onvoiceschanged = initVoices;
    }
    
    return () => {
      if (synth.current) {
        synth.current.onvoiceschanged = null;
      }
    };
  }, []);
  
  // Nettoyer les timeouts √† la destruction du composant
  useEffect(() => {
    return () => {
      console.log('üßπ Nettoyage lors de la destruction du hook');
      
      // Nettoyer tous les timeouts
      clearAllTimeouts(); 
      
      // Arr√™ter toute synth√®se vocale en cours
      if (synth.current) {
        synth.current.cancel();
      }
      
      // Arr√™ter tout audio en cours
      if (audioElementRef.current) {
        audioElementRef.current.pause();
        audioElementRef.current = null;
      }
      
      // Vider la file d'attente
      audioQueue.current = [];
      isPlayingAudio.current = false;
    };
  }, [clearAllTimeouts]);
  
  // R√©initialiser le guidage vocal lorsque la session change
  useEffect(() => {
    sessionGuidanceStarted.current = false;
    sessionGuidancePhase.current = 0;
    clearAllTimeouts();
  }, [currentSession, currentMeditation, clearAllTimeouts]);
  
  // Arr√™ter le guidage vocal lorsque la session est arr√™t√©e
  useEffect(() => {
    if (!isSessionActive) {
      console.log('üîá Session inactive d√©tect√©e - ARR√äT COMPLET de tout guidage vocal');
      
      // Nettoyer tous les timeouts
      clearAllTimeouts();
      
      // Arr√™ter toute synth√®se vocale en cours
      if (synth.current) {
        synth.current.cancel();
        console.log('üîá Synth√®se vocale arr√™t√©e');
      }
      
      // Arr√™ter tout audio en cours
      if (audioElementRef.current) {
        audioElementRef.current.pause();
        audioElementRef.current.src = '';
        audioElementRef.current = null;
        console.log('üîá Lecture audio arr√™t√©e');
      }
      
      // Arr√™ter l'audio complet en cours (M√©tatron)
      if (fullAudioRef.current) {
        fullAudioRef.current.pause();
        fullAudioRef.current.src = '';
        fullAudioRef.current = null;
        console.log('üîá Audio complet M√©tatron arr√™t√©');
      }
      
      // Vider la file d'attente
      audioQueue.current = [];
      isPlayingAudio.current = false;
      
      sessionGuidanceStarted.current = false;
      sessionGuidancePhase.current = 0;
      console.log('üîÑ √âtat du guidage vocal r√©initialis√©');
    }
  }, [isSessionActive, clearAllTimeouts]);
  
  // Fonction pour parler avec la synth√®se vocale
  const speakWithSynthesis = useCallback((text) => {
    if (!voiceSettings.enabled || !text) return;
    
    try {
      // Arr√™ter toute synth√®se vocale en cours
      if (synth.current) {
        synth.current.cancel();
      }
      
      // Cr√©er une nouvelle utterance
      const utterance = new SpeechSynthesisUtterance(text);
      currentUtterance.current = utterance;
      
      // S√©lectionner une voix fran√ßaise
      if (voices.current.length > 0) {
        utterance.voice = voices.current[0];
      }
      
      // Configurer les param√®tres
      utterance.volume = voiceSettings.volume;
      utterance.rate = 0.9; // L√©g√®rement plus lent pour la clart√©
      utterance.pitch = 1.0;
      utterance.lang = 'fr-FR';
      
      // √âv√©nements
      utterance.onstart = () => {
        console.log('üó£Ô∏è SYNTH√àSE VOCALE:', text.substring(0, 30) + (text.length > 30 ? '...' : ''));
      };
      
      utterance.onend = () => {
        console.log('‚úÖ SYNTH√àSE TERMIN√âE');
        currentUtterance.current = null;
      };
      
      utterance.onerror = (event) => {
        if (event.error === 'interrupted') {
          console.warn('‚ö†Ô∏è SYNTH√àSE INTERROMPUE:', event);
        } else {
          console.error('‚ùå ERREUR SYNTH√àSE:', event);
        }
        currentUtterance.current = null;
      };
      
      // Parler
      synth.current.speak(utterance);
    } catch (error) {
      console.error('‚ùå ERREUR LORS DE LA SYNTH√àSE VOCALE:', error);
    }
  }, [voiceSettings.enabled, voiceSettings.volume]);
  
  // Fonction pour jouer le prochain audio dans la file d'attente
  const playNextInQueue = useCallback(() => {
    if (audioQueue.current.length === 0) {
      isPlayingAudio.current = false;
      console.log('üîá File d\'attente audio vide');
      return;
    }
    
    const nextAudio = audioQueue.current.shift();
    isPlayingAudio.current = true;
    
    console.log('üéµ LECTURE AUDIO:', nextAudio.key, nextAudio.url);
    
    try {
      const audio = new Audio(nextAudio.url);
      audioElementRef.current = audio;
      
      audio.onended = () => {
        console.log('‚úÖ AUDIO TERMIN√â:', nextAudio.key);
        audioElementRef.current = null;
        playNextInQueue();
      };
      
      audio.onerror = (error) => {
        console.error('‚ùå ERREUR AUDIO:', error, nextAudio.url);
        
        // Fallback vers synth√®se vocale
        if (nextAudio.fallbackText) {
          console.log('üîÑ FALLBACK SYNTH√àSE pour:', nextAudio.key, '- Raison:', error.message);
          speakWithSynthesis(nextAudio.fallbackText);
        }
        
        audioElementRef.current = null;
        playNextInQueue();
      };
      
      // D√©finir le volume
      audio.volume = voiceSettings.volume;
      
      // Jouer l'audio
      console.log('üîä LECTURE D√âMARR√âE:', nextAudio.url);
      audio.play()
        .catch(error => {
          console.error('‚ùå ERREUR LECTURE AUDIO:', error, nextAudio.url);
          
          // Fallback vers synth√®se vocale
          if (nextAudio.fallbackText) {
            console.log('üîÑ FALLBACK SYNTH√àSE pour:', nextAudio.key, '- Raison:', error.message);
            speakWithSynthesis(nextAudio.fallbackText);
          }
          
          audioElementRef.current = null;
          playNextInQueue();
        });
    } catch (error) {
      console.error('‚ùå ERREUR CR√âATION AUDIO:', error);
      
      // Fallback vers synth√®se vocale
      if (nextAudio.fallbackText) {
        console.log('üîÑ FALLBACK SYNTH√àSE pour:', nextAudio.key, '- Raison:', error.message);
        speakWithSynthesis(nextAudio.fallbackText);
      }
      
      playNextInQueue();
    }
  }, [voiceSettings.volume, speakWithSynthesis]);
  
  // Fonction pour ajouter un audio √† la file d'attente
  const queueAudio = useCallback((url, key, fallbackText) => {
    console.log('üéµ TENTATIVE LECTURE AUDIO:', url);
    
    // V√©rifier si l'URL existe
    fetch(url, { method: 'HEAD' })
      .then(response => {
        if (response.ok) {
          console.log('‚úÖ FICHIER AUDIO TROUV√â:', url, `(${response.status}) - Cl√©: ${key}`);
          
          // Ajouter √† la file d'attente
          audioQueue.current.push({
            url,
            key,
            fallbackText
          });
          
          // D√©marrer la lecture si rien n'est en cours
          if (!isPlayingAudio.current) {
            playNextInQueue();
          }
        } else {
          console.log('‚ùå FICHIER AUDIO NON TROUV√â:', url, `(${response.status}) - Cl√©: ${key}`);
          
          // Fallback vers synth√®se vocale
          if (fallbackText) {
            console.log('üîÑ FALLBACK SYNTH√àSE pour:', key, '- Raison:', 'Fichier non trouv√©');
            speakWithSynthesis(fallbackText);
          }
        }
      })
      .catch(error => {
        console.error('‚ùå ERREUR V√âRIFICATION AUDIO:', error, url, '- Cl√©:', key);
        
        // Fallback vers synth√®se vocale
        if (fallbackText) {
          console.log('üîÑ FALLBACK SYNTH√àSE pour:', key, '- Raison:', error.message);
          speakWithSynthesis(fallbackText);
        }
      });
  }, [playNextInQueue, speakWithSynthesis]);
  
  // Fonction pour jouer un fichier audio complet (pour les m√©ditations avec un seul fichier)
  const playFullAudio = useCallback((audioPath, fallbackText) => {
    if (!voiceSettings.enabled) return;
    
    // V√©rifier que la session est toujours active
    if (!isSessionActive) {
      console.log('üîá Session inactive, annulation lecture audio complet');
      return;
    }
    
    console.log('üéµ TENTATIVE LECTURE AUDIO COMPLET:', audioPath);
    
    // V√©rifier que le fallbackText n'est pas trop long pour √©viter les plantages
    if (fallbackText && fallbackText.length > 500) {
      console.warn('‚ö†Ô∏è Texte de fallback tr√®s long, risque de plantage de la synth√®se vocale');
      console.log('üìè Longueur du texte:', fallbackText.length, 'caract√®res');
    }
    
    // V√©rifier si l'URL existe
    fetch(audioPath, { method: 'HEAD' })
      .then(response => {
        console.log('üì° R√©ponse serveur:', response.status, response.statusText);
        if (response.ok) {
          console.log('‚úÖ FICHIER AUDIO COMPLET TROUV√â:', audioPath, `(${response.status})`);
          
          try {
            const audio = new Audio(audioPath);
            fullAudioRef.current = audio;
            
            // Logs d√©taill√©s pour le debug
            audio.onloadstart = () => {
              console.log('üîÑ D√©but du chargement audio:', audioPath);
            };
            
            audio.oncanplay = () => {
              console.log('‚úÖ Audio pr√™t √† √™tre jou√©:', audioPath);
            };
            
            audio.onloadeddata = () => {
              console.log('üìä Donn√©es audio charg√©es:', audioPath);
            };
            
            audio.onended = () => {
              console.log('‚úÖ AUDIO COMPLET TERMIN√â:', audioPath);
              fullAudioRef.current = null;
              
              // V√©rifier si la session est toujours active apr√®s la fin de l'audio
              if (!isSessionActive) {
                console.log('üîá Session inactive apr√®s fin audio, pas de message de fin');
                return;
              }
            };
            
            audio.onerror = (error) => {
              console.error('‚ùå ERREUR AUDIO COMPLET:', audioPath);
              console.error('üìÑ D√©tails de l\'erreur audio:', {
                errorCode: error.target?.error?.code,
                errorMessage: error.target?.error?.message,
                networkState: error.target?.networkState,
                readyState: error.target?.readyState,
                src: error.target?.src,
                currentTime: error.target?.currentTime,
                duration: error.target?.duration
              });
              
              // Diagnostic sp√©cifique pour les erreurs courantes
              if (error.target?.error?.code === 4) {
                console.error('üö´ ERREUR MEDIA_ELEMENT_ERROR: Fichier audio corrompu ou format non support√©');
                console.log('üí° SOLUTION: R√©-encoder le fichier metatron.mp3 en MP3 standard (128kbps, 44.1kHz)');
              } else if (error.target?.error?.code === 2) {
                console.error('üåê ERREUR NETWORK: Probl√®me de r√©seau ou fichier non accessible');
              } else if (error.target?.error?.code === 3) {
                console.error('üîß ERREUR DECODE: Impossible de d√©coder le fichier audio');
              }
              
              // Fallback vers synth√®se vocale
              if (fallbackText) {
                console.log('üîÑ FALLBACK SYNTH√àSE pour audio complet - Raison: Erreur audio code', error.target?.error?.code);
                try {
                  speakWithSynthesis(fallbackText);
                } catch (synthError) {
                  console.error('‚ùå ERREUR SYNTH√àSE VOCALE FALLBACK:', synthError);
                }
              }
              
              fullAudioRef.current = null;
            };
            
            // D√©finir le volume
            audio.volume = voiceSettings.volume;
            
            // Jouer l'audio
            console.log('üîä LECTURE AUDIO COMPLET D√âMARR√âE:', audioPath);
            audio.play()
              .catch(error => {
                console.error('‚ùå ERREUR LECTURE AUDIO COMPLET:', error);
                console.error('üìÑ D√©tails play() error:', error.name, error.message);
                
                // Fallback vers synth√®se vocale
                if (fallbackText) {
                  console.log('üîÑ FALLBACK SYNTH√àSE pour audio complet - Raison: Erreur play()');
                  try {
                    speakWithSynthesis(fallbackText);
                  } catch (synthError) {
                    console.error('‚ùå ERREUR SYNTH√àSE VOCALE FALLBACK:', synthError);
                  }
                }
                
                fullAudioRef.current = null;
              });
          } catch (error) {
            console.error('‚ùå ERREUR CR√âATION AUDIO COMPLET:', error);
            
            // Fallback vers synth√®se vocale
            if (fallbackText) {
              console.log('üîÑ FALLBACK SYNTH√àSE pour audio complet - Raison: Erreur cr√©ation');
              try {
                speakWithSynthesis(fallbackText);
              } catch (synthError) {
                console.error('‚ùå ERREUR SYNTH√àSE VOCALE FALLBACK:', synthError);
              }
            }
          }
        } else {
          console.error('‚ùå FICHIER AUDIO COMPLET NON ACCESSIBLE:', audioPath, `(${response.status} ${response.statusText})`);
          
          if (response.status === 429) {
            console.error('üö´ ERREUR 429: Trop de requ√™tes - GitHub bloque l\'acc√®s direct aux fichiers');
            console.log('üí° SOLUTION: Utiliser GitHub Pages ou un CDN pour servir les fichiers audio');
          }
          
          // Fallback vers synth√®se vocale
          if (fallbackText) {
            console.log('üîÑ FALLBACK SYNTH√àSE pour audio complet - Raison: Fichier non accessible');
            try {
              speakWithSynthesis(fallbackText);
            } catch (synthError) {
              console.error('‚ùå ERREUR SYNTH√àSE VOCALE FALLBACK:', synthError);
            }
          }
        }
      })
      .catch(error => {
        console.error('‚ùå ERREUR R√âSEAU V√âRIFICATION AUDIO:', error);
        console.error('üìÑ D√©tails r√©seau:', error.name, error.message);
        
        // Fallback vers synth√®se vocale
        if (fallbackText) {
          console.log('üîÑ FALLBACK SYNTH√àSE pour audio complet - Raison: Erreur r√©seau');
          try {
            speakWithSynthesis(fallbackText);
          } catch (synthError) {
            console.error('‚ùå ERREUR SYNTH√àSE VOCALE FALLBACK:', synthError);
          }
        }
      });
  }, [voiceSettings.enabled, voiceSettings.volume, speakWithSynthesis]);
  
  // Fonction principale pour parler (avec audio ou synth√®se)
  const speak = useCallback((text, audioKey = null) => {
    if (!voiceSettings.enabled || !text) return;
    
    // √âviter les r√©p√©titions trop rapproch√©es
    const now = Date.now();
    if (now - lastSpeakTime.current < 500) {
      console.log('‚è±Ô∏è Trop rapide, ignor√©:', text.substring(0, 30));
      return;
    }
    lastSpeakTime.current = now;
    
    // Essayer d'abord de trouver un fichier audio correspondant
    const sessionType = currentSession;
    // Utiliser directement audioKey s'il est fourni
    const gender = voiceSettings.gender;
    
    // Construire le chemin du fichier audio en fonction du type de session
    let audioPath = null;
    
    // V√©rifier les fichiers audio de m√©ditation en premier
    if (currentSession === 'meditation' && currentMeditation) {
      // Cas sp√©cial pour M√©tatron - fichier audio complet
      if (currentMeditation === 'metatron') {
        audioPath = `/audio/meditation/${gender}/metatron.mp3`;
        audioKey = 'metatron-complete';
        console.log(`üåü M√©ditation M√©tatron - Fichier audio complet: ${audioPath}`);
      } else {
      const meditationData = meditations[currentMeditation] || spiritualMeditations[currentMeditation];
      if (meditationData && meditationData.audioFiles && audioKey) {
        const fileName = meditationData.audioFiles[audioKey];
        if (fileName) {
          audioPath = `/audio/meditation/${gender}/${fileName}.mp3`;
          console.log(`üé§ Tentative de lecture audio de m√©ditation: ${audioPath} (${audioKey})`);
        }
      }
      }
    } else if (sessionType === 'switch') {
      // Essayer de trouver un fichier audio pour SOS Stress
      if (text.includes('Bienvenue dans votre bulle')) {
        audioPath = `/audio/sos-stress/${gender}/welcome.mp3`;
        audioKey = 'welcome';
      } else if (text.includes('Inspirez le calme')) {
        audioPath = `/audio/sos-stress/${gender}/breathe-calm.mp3`;
        audioKey = 'breathe-calm';
      } else if (text.includes('Vos pieds touchent le sol')) {
        audioPath = `/audio/sos-stress/${gender}/grounding.mp3`;
        audioKey = 'grounding';
      } else if (text.includes('Soufflez doucement')) {
        audioPath = `/audio/sos-stress/${gender}/breathe-softly.mp3`;
        audioKey = 'breathe-softly';
      } else if (text.includes('Accueillez l\'air frais')) {
        audioPath = `/audio/sos-stress/${gender}/breathe-fresh.mp3`;
        audioKey = 'breathe-fresh';
      } else if (text.includes('Le stress s\'√©vapore')) {
        audioPath = `/audio/sos-stress/${gender}/stress-release.mp3`;
        audioKey = 'stress-release';
      } else if (text.includes('Rel√¢chez tout')) {
        audioPath = `/audio/sos-stress/${gender}/breathe-release.mp3`;
        audioKey = 'breathe-release';
      } else if (text.includes('Vous retrouvez votre centre')) {
        audioPath = `/audio/sos-stress/${gender}/center-peace.mp3`;
        audioKey = 'center-peace';
      } else if (text.includes('Parfait. Vous avez retrouv√©')) {
        audioPath = `/audio/sos-stress/${gender}/completion.mp3`;
        audioKey = 'completion';
      }
    } else if (sessionType === 'scan') {
      // Essayer de trouver un fichier audio pour Scan Corporel
      if (text.includes('Bienvenue dans cette s√©ance de scan')) {
        audioPath = `/audio/scan-corporel/${gender}/welcome.mp3`;
        audioKey = 'welcome';
      } else if (text.includes('Portez votre attention sur le sommet')) {
        audioPath = `/audio/scan-corporel/${gender}/head.mp3`;
        audioKey = 'head';
      } else if (text.includes('Descendez vers votre visage')) {
        audioPath = `/audio/scan-corporel/${gender}/face.mp3`;
        audioKey = 'face';
      } else if (text.includes('Votre cou et vos √©paules')) {
        audioPath = `/audio/scan-corporel/${gender}/neck.mp3`;
        audioKey = 'neck';
      } else if (text.includes('Votre poitrine s\'ouvre')) {
        audioPath = `/audio/scan-corporel/${gender}/chest.mp3`;
        audioKey = 'chest';
      } else if (text.includes('Votre dos se d√©tend')) {
        audioPath = `/audio/scan-corporel/${gender}/back.mp3`;
        audioKey = 'back';
      } else if (text.includes('Votre ventre se gonfle')) {
        audioPath = `/audio/scan-corporel/${gender}/abdomen.mp3`;
        audioKey = 'abdomen';
      } else if (text.includes('Vos hanches et votre bassin')) {
        audioPath = `/audio/scan-corporel/${gender}/hips.mp3`;
        audioKey = 'hips';
      } else if (text.includes('Vos cuisses')) {
        audioPath = `/audio/scan-corporel/${gender}/thighs.mp3`;
        audioKey = 'thighs';
      } else if (text.includes('Vos genoux')) {
        audioPath = `/audio/scan-corporel/${gender}/knees.mp3`;
        audioKey = 'knees';
      } else if (text.includes('Vos mollets')) {
        audioPath = `/audio/scan-corporel/${gender}/calves.mp3`;
        audioKey = 'calves';
      } else if (text.includes('Vos chevilles')) {
        audioPath = `/audio/scan-corporel/${gender}/ankles.mp3`;
        audioKey = 'ankles';
      } else if (text.includes('Vos pieds')) {
        audioPath = `/audio/scan-corporel/${gender}/feet.mp3`;
        audioKey = 'feet';
      } else if (text.includes('Une vague de bien-√™tre')) {
        audioPath = `/audio/scan-corporel/${gender}/wholebody.mp3`;
        audioKey = 'wholebody';
      } else if (text.includes('Observez votre respiration')) {
        audioPath = `/audio/scan-corporel/${gender}/breathing.mp3`;
        audioKey = 'breathing';
      } else if (text.includes('Prenez conscience de votre corps')) {
        audioPath = `/audio/scan-corporel/${gender}/awareness.mp3`;
        audioKey = 'awareness';
      } else if (text.includes('Restez dans cet √©tat')) {
        audioPath = `/audio/scan-corporel/${gender}/presence.mp3`;
        audioKey = 'presence';
      } else if (text.includes('Progressivement, reprenez conscience')) {
        audioPath = `/audio/scan-corporel/${gender}/completion.mp3`;
        audioKey = 'completion';
      }
    } else if (sessionType === 'meditation' && currentMeditation === 'gratitude') {
      // Essayer de trouver un fichier audio pour M√©ditation Gratitude
      if (text.includes('Bienvenue dans cette m√©ditation de gratitude')) {
        audioPath = `/audio/meditation/${gender}/gratitude-installation.mp3`;
        audioKey = 'gratitude-installation';
      } else if (text.includes('Commen√ßons par √©tablir un rythme respiratoire')) {
        audioPath = `/audio/meditation/${gender}/gratitude-coherence-setup.mp3`;
        audioKey = 'gratitude-coherence-setup';
      } else if (text.includes('Portez maintenant votre attention sur votre c≈ìur')) {
        audioPath = `/audio/meditation/${gender}/gratitude-breathing-heart.mp3`;
        audioKey = 'gratitude-breathing-heart';
      } else if (text.includes('√âveillez maintenant le sentiment de gratitude')) {
        audioPath = `/audio/meditation/${gender}/gratitude-awakening.mp3`;
        audioKey = 'gratitude-awakening';
      } else if (text.includes('Inspirez... et pensez √† une chose')) {
        audioPath = `/audio/meditation/${gender}/gratitude-first.mp3`;
        audioKey = 'gratitude-first';
      } else if (text.includes('√âlargissez maintenant votre gratitude vers les personnes')) {
        audioPath = `/audio/meditation/${gender}/gratitude-loved-ones.mp3`;
        audioKey = 'gratitude-loved-ones';
      } else if (text.includes('Dirigez maintenant votre gratitude vers votre corps')) {
        audioPath = `/audio/meditation/${gender}/gratitude-body.mp3`;
        audioKey = 'gratitude-body';
      } else if (text.includes('√âlargissez encore votre gratitude vers la nature')) {
        audioPath = `/audio/meditation/${gender}/gratitude-nature.mp3`;
        audioKey = 'gratitude-nature';
      } else if (text.includes('Ancrez maintenant cette √©nergie de gratitude')) {
        audioPath = `/audio/meditation/${gender}/gratitude-anchoring.mp3`;
        audioKey = 'gratitude-anchoring';
      } else if (text.includes('Int√©grez pleinement cette √©nergie de gratitude')) {
        audioPath = `/audio/meditation/${gender}/gratitude-integration.mp3`;
        audioKey = 'gratitude-integration';
      } else if (text.includes('Doucement, prenez une respiration plus profonde. Remerciez-vous')) {
        audioPath = `/audio/meditation/${gender}/gratitude-conclusion.mp3`;
        audioKey = 'gratitude-conclusion';
      }
    } else if (sessionType === 'meditation' && currentMeditation === 'metatron') {
      // Essayer de trouver un fichier audio pour M√©ditation M√©tatron
      if (text.includes('Bienvenue dans cette m√©ditation d\'invocation')) {
        audioPath = `/audio/meditation/${gender}/metatron-welcome.mp3`;
        audioKey = 'metatron-welcome';
      } else if (text.includes('√î Metatron, ange de la Pr√©sence')) {
        audioPath = `/audio/meditation/${gender}/metatron-invocation.mp3`;
        audioKey = 'metatron-invocation';
      } else if (text.includes('Que ta lumi√®re entoure mon esprit')) {
        audioPath = `/audio/meditation/${gender}/metatron-light.mp3`;
        audioKey = 'metatron-light';
      } else if (text.includes('Toi qui √©cris dans les Livres C√©lestes')) {
        audioPath = `/audio/meditation/${gender}/metatron-memory.mp3`;
        audioKey = 'metatron-memory';
      } else if (text.includes('Toi qui transmets la pens√©e divine')) {
        audioPath = `/audio/meditation/${gender}/metatron-inspiration.mp3`;
        audioKey = 'metatron-inspiration';
      } else if (text.includes('Entoure-moi de ton Cube sacr√©')) {
        audioPath = `/audio/meditation/${gender}/metatron-protection.mp3`;
        audioKey = 'metatron-protection';
      } else if (text.includes('Metatron, Archange de feu blanc')) {
        audioPath = `/audio/meditation/${gender}/metatron-elevation.mp3`;
        audioKey = 'metatron-elevation';
      }
    } else if (sessionType === 'meditation' && currentMeditation === 'abundance') {
      // Essayer de trouver un fichier audio pour M√©ditation Abondance
      if (text.includes('Bienvenue dans cette m√©ditation')) {
        audioPath = `/audio/meditation/${gender}/abundance-introduction.mp3`;
        audioKey = 'abundance-introduction';
      } else if (text.includes('Inspirez profond√©ment par le nez pendant 5 secondes')) {
        audioPath = `/audio/meditation/${gender}/abundance-rhythm-start.mp3`;
        audioKey = 'abundance-rhythm-start';
      } else if (text.includes('Inspirez... l\'univers vous remplit')) {
        audioPath = `/audio/meditation/${gender}/abundance-energy-breath.mp3`;
        audioKey = 'abundance-energy-breath';
      } else if (text.includes('Inspirez... accueillez l\'abondance')) {
        audioPath = `/audio/meditation/${gender}/abundance-abundance-breath.mp3`;
        audioKey = 'abundance-abundance-breath';
      } else if (text.includes('Votre c≈ìur entre en coh√©rence')) {
        audioPath = `/audio/meditation/${gender}/abundance-coherence.mp3`;
        audioKey = 'abundance-coherence';
      } else if (text.includes('Maintenant, tout en gardant ce rythme respiratoire, visualisez')) {
        audioPath = `/audio/meditation/${gender}/abundance-visualize.mp3`;
        audioKey = 'abundance-visualize';
      } else if (text.includes('Inspirez... voyez votre d√©sir comme d√©j√† r√©alis√©')) {
        audioPath = `/audio/meditation/${gender}/abundance-realization-breath.mp3`;
        audioKey = 'abundance-realization-breath';
      } else if (text.includes('Inspirez... impr√©gnez chaque cellule')) {
        audioPath = `/audio/meditation/${gender}/abundance-cellular-breath.mp3`;
        audioKey = 'abundance-cellular-breath';
      } else if (text.includes('Votre c≈ìur coh√©rent amplifie')) {
        audioPath = `/audio/meditation/${gender}/abundance-amplify.mp3`;
        audioKey = 'abundance-amplify';
      } else if (text.includes('Inspirez... Je suis digne de recevoir')) {
        audioPath = `/audio/meditation/${gender}/abundance-worthy-breath.mp3`;
        audioKey = 'abundance-worthy-breath';
      } else if (text.includes('Inspirez... sentez la joie de la r√©alisation')) {
        audioPath = `/audio/meditation/${gender}/abundance-joy-breath.mp3`;
        audioKey = 'abundance-joy-breath';
      } else if (text.includes('L\'univers conspire en votre faveur')) {
        audioPath = `/audio/meditation/${gender}/abundance-universe.mp3`;
        audioKey = 'abundance-universe';
      } else if (text.includes('Inspirez... Je co-cr√©e avec l\'univers')) {
        audioPath = `/audio/meditation/${gender}/abundance-cocreate-breath.mp3`;
        audioKey = 'abundance-cocreate-breath';
      } else if (text.includes('Inspirez... amplifiez le sentiment de gratitude')) {
        audioPath = `/audio/meditation/${gender}/abundance-gratitude-breath.mp3`;
        audioKey = 'abundance-gratitude-breath';
      } else if (text.includes('Continuez ce rythme de respiration consciente')) {
        audioPath = `/audio/meditation/${gender}/abundance-manifestation-cycle.mp3`;
        audioKey = 'abundance-manifestation-cycle';
      } else if (text.includes('Continuez √† respirer en coh√©rence cardiaque, sachant que votre d√©sir')) {
        audioPath = `/audio/meditation/${gender}/abundance-anchor.mp3`;
        audioKey = 'abundance-anchor';
      } else if (text.includes('Inspirez... Je suis align√© avec mes d√©sirs')) {
        audioPath = `/audio/meditation/${gender}/abundance-alignment.mp3`;
        audioKey = 'abundance-alignment';
      } else if (text.includes('Votre c≈ìur coh√©rent est votre boussole')) {
        audioPath = `/audio/meditation/${gender}/abundance-compass.mp3`;
        audioKey = 'abundance-compass';
      } else if (text.includes('Doucement, prenez une respiration plus profonde. Remerciez-vous')) {
        audioPath = `/audio/meditation/${gender}/abundance-completion.mp3`;
        audioKey = 'abundance-completion';
      }
    }
    
    // Si un fichier audio a √©t√© trouv√©, essayer de le jouer
    if (audioPath && audioKey) {
      console.log(`üé§ ${Date.now() % 100000}ms: ${audioKey} - ${text.substring(0, 30)}... (${gender}) - PREMIUM`);
      queueAudio(audioPath, audioKey, text);
    } else {
      // Sinon, utiliser la synth√®se vocale
      console.log(`üó£Ô∏è ${Date.now() % 100000}ms: SYNTH√àSE DIRECTE: "${text.substring(0, 30)}..."`);
      speakWithSynthesis(text);
    }
  }, [voiceSettings.enabled, voiceSettings.gender, currentSession, currentMeditation, queueAudio, speakWithSynthesis]);
  
  // Fonction pour arr√™ter toute parole
  const stop = useCallback(() => {
    // Arr√™ter la synth√®se vocale
    console.log('üîá ARR√äT FORC√â de toute parole et guidage'); 
    if (synth.current) {
      synth.current.cancel();
    }
    
    // Arr√™ter l'audio en cours
    if (audioElementRef.current) {
      console.log('üîá Arr√™t forc√© de l\'audio en cours:', audioElementRef.current.src);
      audioElementRef.current.pause();
      audioElementRef.current.src = '';
      audioElementRef.current = null;
    }
    
    // Arr√™ter l'audio complet en cours
    if (fullAudioRef.current) {
      fullAudioRef.current.pause();
      fullAudioRef.current = null;
    }
    
    // Arr√™ter tous les √©l√©ments audio en cours
    document.querySelectorAll('audio').forEach(audio => {
      console.log('üîá Arr√™t forc√© d\'un √©l√©ment audio:', audio.src);
      audio.pause();
      audio.src = '';
    });
    
    // Vider la file d'attente
    audioQueue.current = [];
    isPlayingAudio.current = false;

    // Arr√™t direct de la synth√®se vocale
    window.speechSynthesis.cancel();
    
    // R√©initialiser les variables de guidage
    console.log('üîÑ R√©initialisation compl√®te du syst√®me de guidage vocal');
    sessionGuidanceStarted.current = false;
    sessionGuidancePhase.current = 0;
    
    // Nettoyer tous les timeouts possibles
    const highestId = setTimeout(() => {}, 0);
    for (let i = 0; i < highestId; i++) {
      clearTimeout(i);
    }
    
    console.log('üîá Toute parole arr√™t√©e');
    return true;
  }, [clearAllTimeouts]);
  
  // Fonction pour d√©marrer le guidage vocal pour la session SOS Stress
  const startSosStressGuidance = useCallback(() => {
    if (!voiceSettings.enabled || !isSessionActive) {
      console.log('üîá Guidage vocal SWITCH/SOS d√©sactiv√© ou session inactive');
      return false;
    }
    
    // Nettoyer tout timeout existant pour √©viter les doublons
    clearAllTimeouts();
    
    console.log('üö® D√âMARRAGE SWITCH/SOS STRESS - DIAGNOSTIC COMPLET', voiceSettings.gender === 'female' ? '(Claire)' : '(Thierry)');
    
    // Tester tous les fichiers audio pour SOS Stress
    console.log('üîç TEST DES FICHIERS AUDIO SWITCH/SOS STRESS...');
    const gender = voiceSettings.gender;
    const filesToTest = [
      'welcome', 'breathe-calm', 'grounding', 'breathe-softly', 
      'breathe-fresh', 'stress-release', 'breathe-release', 
      'center-peace', 'completion'
    ];
    
    filesToTest.forEach(file => {
      const url = `/audio/sos-stress/${gender}/${file}.mp3`;
      fetch(url, { method: 'HEAD' })
        .then(response => {
          console.log(`${response.ok ? '‚úÖ' : '‚ùå'} ${url} (${response.status})`);
        })
        .catch(error => {
          console.error('‚ùå Erreur test fichier:', url, error);
        });
    });
    
    // S√©quence 1 - Message d'accueil (0s)
    createTrackedTimeout(() => {
      console.log('üéØ SOS: welcome (0.5s - accueil)');
      speak("Bienvenue dans votre bulle de calme. Posez vos pieds bien √† plat sur le sol. D√©tendez vos √©paules.");
    }, 500);
    
    // S√©quence 2 - Inspiration (12s)
    createTrackedTimeout(() => {
      console.log('üéØ SOS: breathe-calm (12s - inspiration)');
      speak("Inspirez le calme");
    }, 12000);
    
    // S√©quence 3 - Ancrage (28s)
    createTrackedTimeout(() => {
      console.log('üéØ SOS: grounding (28s - ancrage)');
      speak("Vos pieds touchent le sol. Vous √™tes ancr√©, solide, stable.");
    }, 28000);
    
    // S√©quence 4 - Expiration (37s)
    createTrackedTimeout(() => {
      console.log('üéØ SOS: breathe-softly (37s - expiration)');
      speak("Soufflez doucement");
    }, 37000);
    
    // S√©quence 5 - Inspiration (48s)
    createTrackedTimeout(() => {
      console.log('üéØ SOS: breathe-fresh (48s - inspiration)');
      speak("Accueillez l'air frais");
    }, 48000);
    
    // S√©quence 6 - Lib√©ration (58s)
    createTrackedTimeout(() => {
      console.log('üéØ SOS: stress-release (58s - lib√©ration)');
      speak("Le stress s'√©vapore √† chaque souffle. Votre corps se d√©tend profond√©ment.");
    }, 58000);
    
    // S√©quence 7 - Expiration (67s)
    createTrackedTimeout(() => {
      console.log('üéØ SOS: breathe-release (67s - expiration)');
      speak("Rel√¢chez tout");
    }, 67000);
    
    // S√©quence 8 - Recentrage (78s)
    createTrackedTimeout(() => {
      console.log('üéØ SOS: center-peace (78s - recentrage)');
      speak("Vous retrouvez votre centre. Tout va bien. Vous √™tes en s√©curit√©.");
    }, 78000);
    
    // S√©quence 9 - Message de fin (85s)
    createTrackedTimeout(() => {
      console.log('üéØ SOS: completion (85s - fin)');
      speak("Parfait. Vous avez retrouv√© votre calme int√©rieur. Gardez cette sensation avec vous.");
    }, 85000);
    
    return true;
  }, [voiceSettings.enabled, voiceSettings.gender, isSessionActive, speak, clearAllTimeouts, createTrackedTimeout]);
  
  // Fonction pour d√©marrer le guidage vocal pour la session Scan Corporel
  const startScanGuidance = useCallback(() => {
    if (!voiceSettings.enabled || !isSessionActive) {
      console.log('üîá Guidage vocal d√©sactiv√© ou session inactive');
      return false;
    }
    
    console.log('üß† D√âMARRAGE SCAN CORPOREL', voiceSettings.gender === 'female' ? '(Claire)' : '(Thierry)');
    
    // Nettoyer tout timeout existant pour √©viter les doublons
    clearAllTimeouts(); 
    
    // S√©quence 1 - Message d'accueil (0s)
    speak("Bienvenue dans cette s√©ance de scan corporel. Installez-vous confortablement, fermez les yeux si vous le souhaitez. Nous allons explorer chaque partie de votre corps pour une relaxation profonde.");
    
    // S√©quence 2 - T√™te (30s)
    createTrackedTimeout(() => {
      speak("Portez votre attention sur le sommet de votre t√™te. Sentez cette zone se d√©tendre compl√®tement.");
    }, 30000);
    
    // S√©quence 3 - Visage (60s)
    createTrackedTimeout(() => {
      speak("Descendez vers votre visage. Rel√¢chez votre front, vos sourcils, vos paupi√®res. D√©tendez vos m√¢choires, votre langue, votre gorge.");
    }, 60000);
    
    // S√©quence 4 - Cou (90s)
    createTrackedTimeout(() => {
      speak("Votre cou et vos √©paules se rel√¢chent maintenant. Laissez partir toute tension accumul√©e dans cette zone.");
    }, 90000);
    
    // S√©quence 5 - Poitrine (120s)
    createTrackedTimeout(() => {
      speak("Votre poitrine s'ouvre et se d√©tend √† chaque respiration. Sentez l'air qui entre et qui sort librement.");
    }, 120000);
    
    // S√©quence 6 - Dos (150s)
    createTrackedTimeout(() => {
      speak("Votre dos se d√©tend vert√®bre par vert√®bre, du haut vers le bas. Chaque vert√®bre s'aligne parfaitement.");
    }, 150000);
    
    // S√©quence 7 - Ventre (180s)
    createTrackedTimeout(() => {
      speak("Votre ventre se gonfle et se d√©gonfle naturellement, sans effort. Sentez une douce chaleur s'y r√©pandre.");
    }, 180000);
    
    // S√©quence 8 - Hanches (210s)
    createTrackedTimeout(() => {
      speak("Vos hanches et votre bassin se rel√¢chent compl√®tement. Sentez le poids de votre corps s'enfoncer dans le support.");
    }, 210000);
    
    // S√©quence 9 - Cuisses (240s)
    createTrackedTimeout(() => {
      speak("Vos cuisses se d√©tendent profond√©ment. Toute tension s'√©vapore √† chaque expiration.");
    }, 240000);
    
    // S√©quence 10 - Genoux (255s)
    createTrackedTimeout(() => {
      speak("Vos genoux se d√©tendent. Sentez l'espace dans vos articulations.");
    }, 255000);
    
    // S√©quence 11 - Mollets (270s)
    createTrackedTimeout(() => {
      speak("Vos mollets se rel√¢chent enti√®rement. Sentez l'√©nergie circuler librement.");
    }, 270000);
    
    // S√©quence 12 - Chevilles (285s)
    createTrackedTimeout(() => {
      speak("Vos chevilles se d√©tendent. Sentez l'espace dans ces articulations.");
    }, 285000);
    
    // S√©quence 13 - Pieds (300s)
    createTrackedTimeout(() => {
      speak("Vos pieds, jusqu'au bout de vos orteils, sont maintenant compl√®tement d√©tendus et lourds.");
    }, 300000);
    
    // S√©quence 14 - Corps entier (360s)
    createTrackedTimeout(() => {
      speak("Une vague de bien-√™tre parcourt maintenant tout votre corps, de la t√™te aux pieds. Vous √™tes dans un √©tat de relaxation profonde.");
    }, 360000);
    
    // S√©quence 15 - Respiration (420s)
    createTrackedTimeout(() => {
      speak("Observez votre respiration, calme et r√©guli√®re. Chaque inspiration vous apporte √©nergie et vitalit√©. Chaque expiration approfondit votre relaxation.");
    }, 420000);
    
    // S√©quence 16 - Conscience (480s)
    createTrackedTimeout(() => {
      speak("Prenez conscience de votre corps dans son ensemble, parfaitement d√©tendu et en harmonie.");
    }, 480000);
    
    // S√©quence 17 - Pr√©sence (540s)
    createTrackedTimeout(() => {
      speak("Restez dans cet √©tat de relaxation profonde, en pleine conscience de votre corps et de votre respiration.");
    }, 540000);
    
    // S√©quence 18 - Fin (570s)
    createTrackedTimeout(() => {
      speak("Progressivement, reprenez conscience de votre environnement. Bougez doucement vos doigts, vos orteils. √âtirez-vous si vous le souhaitez. Votre corps est maintenant compl√®tement d√©tendu et votre esprit apais√©.");
    }, 570000);
    
    return true;
  }, [voiceSettings.enabled, voiceSettings.gender, isSessionActive, speak, clearAllTimeouts, createTrackedTimeout]);
  
  // Fonction pour d√©marrer le guidage vocal pour la session de coh√©rence cardiaque
  const startCoherenceGuidance = useCallback(() => {
    if (!voiceSettings.enabled || !isSessionActive) {
      console.log('üîá Guidage vocal d√©sactiv√© ou session inactive');
      return false;
    }
    
    console.log('üíì D√âMARRAGE COH√âRENCE CARDIAQUE', voiceSettings.gender === 'female' ? '(Claire)' : '(Thierry)');
    
    // Nettoyer tout timeout existant pour √©viter les doublons
    clearAllTimeouts(); 
    
    // Message d'accueil
    speak("Bienvenue dans votre session de coh√©rence cardiaque. Installez-vous confortablement et suivez le rythme respiratoire.");
    
    // Message √† mi-session (calcul√© dynamiquement)
    const sessionDuration = 300; // 5 minutes par d√©faut
    const midPoint = Math.floor(sessionDuration / 2) * 1000;
    
    createTrackedTimeout(() => {
      speak("Vous √™tes √† mi-parcours. Continuez ce rythme respiratoire qui harmonise votre c≈ìur et votre esprit.");
    }, midPoint);
    
    // Message √† 1 minute de la fin
    const oneMinuteBeforeEnd = (sessionDuration - 60) * 1000;
    
    createTrackedTimeout(() => {
      speak("Plus qu'une minute. Savourez ces derniers instants de coh√©rence.");
    }, oneMinuteBeforeEnd);
    
    // Message de fin
    const endTime = (sessionDuration - 10) * 1000;
    
    createTrackedTimeout(() => {
      speak("Votre session de coh√©rence cardiaque se termine. Gardez cette harmonie avec vous tout au long de votre journ√©e.");
    }, endTime);
    
    return true;
  }, [voiceSettings.enabled, voiceSettings.gender, isSessionActive, speak, clearAllTimeouts, createTrackedTimeout]);
  
  // Fonction pour d√©marrer le guidage vocal pour n'importe quelle session
  const startSessionGuidance = useCallback(() => {
    if (!voiceSettings.enabled || !isSessionActive) {
      console.log('üîá Guidage vocal d√©sactiv√© ou session inactive');
      return false;
    }
    
    if (sessionGuidanceStarted.current) {
      console.log('‚ö†Ô∏è Guidage vocal d√©j√† d√©marr√©');
      return false;
    }
    
    sessionGuidanceStarted.current = true;
    
    console.log('üé§ D√âMARRAGE GUIDAGE - Session:', currentSession, 'M√©ditation:', currentMeditation);
    
    if (currentSession === 'switch') {
      return startSosStressGuidance();
    } else if (currentSession === 'scan') {
      return startScanGuidance();
    } else if (currentSession === 'coherence') {
      return startCoherenceGuidance();
    } else if (currentSession === 'meditation' && currentMeditation === 'metatron') {
      // Pour la m√©ditation M√©tatron avec fichier audio complet
      console.log('üåü D√âMARRAGE M√âDITATION M√âTATRON');
      const meditationData = spiritualMeditations[currentMeditation] || meditations[currentMeditation];
      if (!meditationData) {
        console.error('‚ùå Donn√©es de m√©ditation M√©tatron non trouv√©es');
        return false;
      }

      console.log('üåü D√©marrage m√©ditation M√©tatron avec fichier audio complet');
      
      // Message d'accueil imm√©diat avec fallback court
      const fallbackMessage = meditationData.fallbackStart || "Bienvenue dans cette m√©ditation spirituelle. Installez-vous confortablement.";
      speak(fallbackMessage);
      
      // Essayer de charger l'audio complet apr√®s 5 secondes
      createTrackedTimeout(() => {
        // V√©rifier que la session est toujours active avant de d√©marrer l'audio
        if (!isSessionActive) {
          console.log('üîá Session inactive, annulation du d√©marrage audio M√©tatron');
          return;
        }
        
        const gender = voiceSettings.gender;
        const audioPath = `/audio/meditation/${gender}/metatron.mp3`;
        const fallbackText = meditationData.fallbackStart; // Utiliser le fallback court
        
        console.log('üéµ TENTATIVE LECTURE M√âTATRON:', audioPath);
        playFullAudio(audioPath, fallbackText);
      }, 5000); // D√©marrage √† 5 secondes
      
      // Programmer les phases de fallback SEULEMENT si l'audio ne marche pas
      // On va les programmer avec une v√©rification de session active
      if (meditationData.guidance.phases) {
        meditationData.guidance.phases.forEach((phaseText, index) => {
          createTrackedTimeout(() => {
            // V√©rifier que la session est toujours active
            if (!isSessionActive) {
              console.log(`üîá Session inactive, annulation phase M√©tatron ${index + 1}`);
              return;
            }
            console.log(`üåü M√©tatron fallback - Phase ${index + 1}`);
            speak(phaseText);
          }, (index + 1) * 45000); // Une phase toutes les 45 secondes
        });
      }
      
      // Message de fin avec v√©rification de session active
      createTrackedTimeout(() => {
        // V√©rifier que la session est toujours active
        if (!isSessionActive) {
          console.log('üîá Session inactive, annulation message de fin M√©tatron');
          return;
        }
        speak(meditationData.guidance.end);
      }, 270000); // 4min 30s

      return true;
    } else if (currentSession === 'meditation' && currentMeditation && currentMeditation !== 'metatron') {
      // Pour les autres m√©ditations
      const meditationData = meditations[currentMeditation];
      if (!meditationData) {
        console.error('‚ùå Donn√©es de m√©ditation non trouv√©es pour:', currentMeditation);
        return false;
      }

      // Message d'accueil
      speak(meditationData.guidance.start, meditationData.audioFiles?.welcome);

      // Programmer les phases avec des d√©lais g√©n√©riques
      meditationData.guidance.phases.forEach((phaseText, index) => {
        // D√©lai simple: 30s par phase
        createTrackedTimeout(() => {
          console.log(`üßò M√©ditation ${currentMeditation} - Phase ${index + 1}`);
          speak(phaseText);
        }, (index + 1) * 30000);
      });

      // Message de fin
      createTrackedTimeout(() => {
        speak(meditationData.guidance.end);
      }, meditationData.duration * 1000 - 10000); // 10 secondes avant la fin

      return true;
    } else {
      // Pour les autres sessions, utiliser un guidage g√©n√©rique
      speak("Bienvenue dans votre session. Suivez le rythme respiratoire et laissez-vous guider.");
      return true;
    }
  }, [currentSession, currentMeditation, startSosStressGuidance, startScanGuidance, startCoherenceGuidance, speak, voiceSettings.enabled, voiceSettings.gender, isSessionActive, createTrackedTimeout, playFullAudio]);
  
  return {
    speak,
    stop,
    clearAllTimeouts: useCallback(() => {
      console.log('üßπ Nettoyage explicite des timeouts demand√©');
      clearAllTimeouts();
      return true;
    }, [clearAllTimeouts]),
    startSessionGuidance: useCallback(() => {
      console.log('üîÑ R√©initialisation du guidage avant d√©marrage');
      // R√©initialiser l'√©tat pour permettre un nouveau d√©marrage
      sessionGuidanceStarted.current = false;
      
      // Nettoyer tous les timeouts existants
      clearAllTimeouts();
      
      return startSessionGuidance();
    }, [startSessionGuidance, clearAllTimeouts]),
    isInitialized: isInitialized.current,
  };
};